{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>This code builds an AI Voice Assisstant.</H1> \n",
    "\n",
    "<p>The code will provide the following features</p>\n",
    "\n",
    "<ol>\n",
    "    <li>Capture mic input</li> \n",
    "    <li>Check audio level of input</li>\n",
    "    <li>If loud enough, record user speech for 5 seconds</li>\n",
    "    <li>This speech is then be saved as an audio file</li>\n",
    "    <li>The audio file is read and transcribed into text</li>\n",
    "    <li>The text is save to a file</li>\n",
    "    <li>LLM access and key is setup</li>\n",
    "    <li>A prompt instruction is created for LLM</li>\n",
    "    <li>The text is read from file</li> \n",
    "    <li>The text is sent to LLM with instructions</li>\n",
    "    <li>The response text is captured from LLM</li>\n",
    "    <li>The response text is written to file</li>\n",
    "    <li>The text response from LLM is read from file</li>\n",
    "    <li>The text is tokenized into sentences</li>\n",
    "    <li>Each sentence is synthesized into audio</li> \n",
    "    <li>A pause is inserted after each sentence</li>\n",
    "    <li>The audio from each sentence is aggregated</li>\n",
    "    <li>The aggregated audio is saved to file</li>\n",
    "    <li>The audio is then played back to the user</li>\n",
    "    <li>This entire process is repeated continuously</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pyaudio                      # To manipulate audio\n",
    "from pydub import AudioSegment      # To manipulate audio\n",
    "import pygame                       # To play audio\n",
    "import struct                       # To grab short integer for volume check\n",
    "import wave                         # To store as wave file\n",
    "import speech_recognition as sr     # Google's speech recognition tool\n",
    "from openai import OpenAI           # OpenAI's api\n",
    "from gtts import gTTS               # text to speech conversion\n",
    "import os                           # for accessing file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the parameters for the \n",
    "# audio stream.\n",
    "param = {\n",
    "    \"format\": pyaudio.paInt16,\n",
    "    \"channels\": 1,\n",
    "    \"rate\": 44100,\n",
    "    \"chunk\": 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen(threshold=5000):\n",
    "    \"\"\"\n",
    "    Listens through the microphone continuous after user\n",
    "    potentially presses a button. It listens for the audio \n",
    "    level to be sufficiently high and then exits\n",
    "    \"\"\"\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open audio stream\n",
    "    stream = p.open(\n",
    "        format=param[\"format\"], \n",
    "        channels=param[\"channels\"], \n",
    "        rate=param[\"rate\"], \n",
    "        input=True, \n",
    "        frames_per_buffer=param[\"chunk\"]\n",
    "    )\n",
    "\n",
    "    # Assume the initial volume of audio is zero\n",
    "    # This is a 16 bit sample value, so it can \n",
    "    # vary between 0 and 65,535\n",
    "    volume = 0\n",
    "\n",
    "    # Iterate and keep checking the audio until the leve\n",
    "    # exceeds the threshold. If it does then we assume\n",
    "    # that this is because there is some speech directed\n",
    "    # at the voice assistant.\n",
    "    while (volume < threshold):\n",
    "        # Read audio stream\n",
    "        rawAudioBytes = stream.read(param[\"chunk\"])\n",
    "\n",
    "        # There are two bytes per frame for \n",
    "        frame_bytes = len(rawAudioBytes)/param[\"chunk\"]\n",
    "\n",
    "        # Use integer division with // to create a\n",
    "        # struct format data type\n",
    "        format = \"%dh\" % (len(rawAudioBytes)/frame_bytes)\n",
    "\n",
    "        # Extract sample data as a magnitude from the\n",
    "        # raw audio byte stream. The audio is in the\n",
    "        # form of a tuple containing all sample volume\n",
    "        # levels\n",
    "        audio = struct.unpack(format, rawAudioBytes)\n",
    "\n",
    "        # Check the maximum volume of the samples\n",
    "        volume = max(audio)\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(file=\"output.wav\", threshold=2000, time=1):\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open audio stream\n",
    "    stream = p.open(\n",
    "        format=param[\"format\"], \n",
    "        channels=param[\"channels\"], \n",
    "        rate=param[\"rate\"], \n",
    "        input=True, \n",
    "        frames_per_buffer=param[\"chunk\"]\n",
    "    )\n",
    "\n",
    "    # Initialize an empty list for the frames\n",
    "    # to be recorded\n",
    "    frames = []\n",
    "\n",
    "    # Assume that the volume is already at the threshold\n",
    "    # when starting the recording\n",
    "    volume = threshold\n",
    "\n",
    "    # Record until the average volume of the audio\n",
    "    # falls below the threshold. We want to record at \n",
    "    # least 'time' seconds before checking volume.\n",
    "    while (volume>=threshold):\n",
    "        # The minimum number of frames to record at a time\n",
    "        # before checking volume\n",
    "        minframes = int(param[\"rate\"] / param[\"chunk\"] * time)\n",
    "\n",
    "        # Create an array of volumes for each time period of recording\n",
    "        volume=[]\n",
    "\n",
    "        # Record data from the microphone\n",
    "        for i in range(0, minframes):\n",
    "            # Read the raw audio of chunk size indicated\n",
    "            rawAudioBytes = stream.read(param[\"chunk\"])\n",
    "\n",
    "            # Store the raw bytes as valid data\n",
    "            frames.append(rawAudioBytes)\n",
    "\n",
    "            # How many bytes in a single frame \n",
    "            frame_bytes = len(rawAudioBytes)/param[\"chunk\"]\n",
    "\n",
    "            # Use integer division with // to create a\n",
    "            # struct format data type\n",
    "            format = \"%dh\" % (len(rawAudioBytes)/frame_bytes)\n",
    "\n",
    "            # Extract sample data as a magnitude from the\n",
    "            # raw audio byte stream. The audio is in the\n",
    "            # form of a tuple containing all sample volume\n",
    "            # levels\n",
    "            audio = struct.unpack(format, rawAudioBytes)\n",
    "\n",
    "            # Check the max volume of the samples\n",
    "            volume.append(max(audio))\n",
    "        \n",
    "        # Grab the max volume in the time period\n",
    "        volume = max(volume) #sum(volume)/len(volume)\n",
    "\n",
    "        print (volume)\n",
    "\n",
    "    # Stop and close the stream once\n",
    "    # recording is over.\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    # set the audio parameters for recording as well\n",
    "    # then concatenate all the frames together into a \n",
    "    # single continuous set of bytes \n",
    "    wf = wave.open(file, 'wb')\n",
    "    wf.setnchannels(param[\"channels\"])\n",
    "    wf.setsampwidth(p.get_sample_size(param[\"format\"]))\n",
    "    wf.setframerate(param[\"rate\"])\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(audiofile=\"output.wav\", textfile=\"output.txt\"):\n",
    "    # Create a new recognizer object\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    # Open a recorded audio file\n",
    "    audio = sr.AudioFile(audiofile)\n",
    "\n",
    "    # Record the audio into the recognizer object\n",
    "    with audio as source:\n",
    "        audio_ = r.record(source)\n",
    "\n",
    "    # Transcribe audio to text\n",
    "    try:\n",
    "        transcription=r.recognize_google(audio_)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return\n",
    "\n",
    "    # Write the text to file\n",
    "    with open(textfile, \"w\") as file:\n",
    "        # Write the variables to the file\n",
    "        file.write(f\"{transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send(requestfile=\"output.txt\", responsefile=\"output_.txt\"):\n",
    "    # Read the text of the request generated by the user\n",
    "    with open(requestfile, 'r') as file:\n",
    "        requesttxt = file.read()\n",
    " \n",
    "    # How many tokens for the transcript and summary text and what are the instructions for \n",
    "    # formating the transcript\n",
    "    tokens=150\n",
    "    instructions=\"Provide a response to the user query. Keep it brief and concise. Remove grammatically incorrect parts of the text from the query.\"\n",
    "    prompt = f\"{instructions}: {requesttxt}\"\n",
    "    key = \"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\"\n",
    "\n",
    "    # Instantiate an openai client\n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    # response = client.completion.create(\n",
    "    #     engine=\"text-davinci-003\",\n",
    "    #     prompt=prompt,\n",
    "    #     max_tokens=tokens\n",
    "    # )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract the summary from the OpenAI API response\n",
    "    responsetxt = completion.choices[0].message.content\n",
    "\n",
    "    # Write the text to file\n",
    "    with open(responsefile, \"w\") as file:\n",
    "        # Write the variables to the file\n",
    "        file.write(f\"{responsetxt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(outputfile = \"output_.mp3\", textfile=\"output_.txt\"):\n",
    "    # Read the text of the request generated by the user\n",
    "    with open(textfile, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # provide a data structure containing \n",
    "    # a mapping for various regional accents\n",
    "    # to be used by gtts\n",
    "    ac={\n",
    "        'gtts':{\n",
    "            'en':{\n",
    "                'au':'com.au',\n",
    "                'uk':'co.uk',\n",
    "                'us':'com',\n",
    "                'ca':'ca',\n",
    "                'in':'co.in',\n",
    "                'ie':'ie',\n",
    "                'za':'co.za',\n",
    "            }\n",
    "\n",
    "        },\n",
    "        'pyttsx':{\n",
    "            'en':{\n",
    "                'uk':'english_rp+f3'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Choose your accent and language\n",
    "    accent = 'uk'\n",
    "    language = 'en'\n",
    "\n",
    "    # Call google text to speech and save audio to mp3\n",
    "    gtts = gTTS(text=text, lang=language, tld = ac['gtts'][language][accent], slow=False)\n",
    "    gtts.save(outputfile)\n",
    "\n",
    "    # Convert mp3 to wav and store\n",
    "    name, ext = os.path.splitext(\"output_.mp3\")\n",
    "    AudioSegment.from_mp3(outputfile).export(name+\".wav\", format=\"wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(audiofile=\"output_.wav\"):\n",
    "    # Initialize pygame mixer\n",
    "    pygame.mixer.init()\n",
    "\n",
    "    # Load the sound\n",
    "    sound = pygame.mixer.Sound(audiofile)\n",
    "\n",
    "    # Play the sound\n",
    "    sound.play()\n",
    "\n",
    "    # Keep the script running until the audio finishes\n",
    "    while pygame.mixer.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for i in range(0,10):\n",
    "        # Listen until audio detected\n",
    "        listen(threshold=12000)\n",
    "        print (\"audio detected\")\n",
    "\n",
    "        # # Record audio to file\n",
    "        record(threshold=7000)\n",
    "        print (\"audio recorded\")\n",
    "\n",
    "        # Extract text from the audio file\n",
    "        extract()\n",
    "        print (\"audio transcribed\")\n",
    "\n",
    "        # Feed the text into LLM and get response\n",
    "        send()\n",
    "        print (\"text sent\")\n",
    "\n",
    "        # Responds to the user in audio format\n",
    "        respond()\n",
    "        print (\"response given\")\n",
    "\n",
    "        # Plays the audio for user\n",
    "        play()\n",
    "        print (\"Plays audio to user\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio detected\n",
      "16021\n",
      "13688\n",
      "1203\n",
      "audio recorded\n",
      "audio transcribed\n",
      "text sent\n",
      "response given\n",
      "Plays audio to user\n",
      "audio detected\n",
      "27506\n",
      "17099\n",
      "994\n",
      "audio recorded\n",
      "audio transcribed\n",
      "text sent\n",
      "response given\n",
      "Plays audio to user\n",
      "audio detected\n",
      "32767\n",
      "1230\n",
      "audio recorded\n",
      "audio transcribed\n",
      "text sent\n",
      "response given\n",
      "Plays audio to user\n",
      "audio detected\n",
      "23669\n",
      "15246\n",
      "13882\n",
      "16372\n",
      "9678\n",
      "882\n",
      "audio recorded\n",
      "audio transcribed\n",
      "text sent\n",
      "response given\n",
      "Plays audio to user\n",
      "audio detected\n",
      "8364\n",
      "4710\n",
      "audio recorded\n",
      "\n",
      "audio transcribed\n",
      "text sent\n",
      "response given\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Plays the audio for user\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlays audio to user\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mplay\u001b[0;34m(audiofile)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Keep the script running until the audio finishes\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39mget_busy():\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
