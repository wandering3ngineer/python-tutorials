'''
Energy & Weather Analytics (Demo)
----------------------------------
This code is demonstration code for analyzing some sample weather and electricity 
meter data from a particular region in the world. The code first visualizes the 
existing data and produces html graphs. It then goes ahead and uses kmeans clustering 
to determine how meter energy consumption patterns over a year may be related to 
establish distinct clusters of meters that can be grouped together as similar. 
An html graph is used to map this data into a map and identify differences in clusters. 
It then brings weather information into the mix to determine the multivariate 
correlation (linear) between various weather parameters such as GHI, Wind, 
Irradiance, etc. and between meter energy consumption. This is then used with 
autoencoders to determine distinct possible load patterns existing among meters 
relative to weather. Highly correlated meteers would exhibit high correlation 
suggesting use of air conditioning to higher levels. 

On HTML Rendering
------------------
Note that rendering times for some of the HTML files generated could be a bit
slow. So be patient when loading. I haven't really done any optimization for
rendering into a web browser

This code, when executed without parameters should take about a minute or
so to fully run and will produce four sets of html graphs that can be 
viewed in a web browser:

On Documentation
----------------
Detailed API documentation is provided as an autogenerated html file called
**main.html**. This is generated using the command 

<pre>pdoc main --html --output-dir . --force</pre>

Additional documentation is embedded directly in the code. 

### Visualization of Energy Analytics Results
There are four different visualizatons that are produced as below. Note that some
limited conclusions can be drawn from analyzing the data. Refer below. The user
need not run the code as the HTML files have already been pre-generated for convenience

Note that the input used for generating visuals are the files:
a. **weather.xlsx** (modified to remove top row from original **weather_original.xlsx**)
b. **electricity.xlsx**


1. **graph_energy_meter.html**
This graph just graphs al the meters for all areas into a single HTML for
viewing the relationship between meters on a month by month and area by area
level. Good for just trying to understand some things about the data. Though
maybe a bit overkill and thus less useful. 

2. **graph_weather_energy_month.html**
This graph contains a yearly view per graph for every meter as organized
on an area by area basis. This is more useful than the previous graph. The 
weather parameters such as temperature, humidity are also graphed ontop of
each graph just to provide a relative baseline for energy consumption patterns. 
Again this graph is purely to better understand and visualize the data. 

3. **graph_energy_meter_clusters.html**
This graph does some ML and takes all the meter energy data for a year
and compares all meters to each other. The more closely clustered these
energy values are after normalization the more likely they are part of a single
cluster of energy consumption patterns. Optimal cluster graph is provided where
the code automatically determines the clusters, then the meters are pinned on
to a map and colour coded by those that have similar energy consumption patterns
And finally distinct cluster mean energies are mapped to show how th clusters vary
across the year in energy consumption. Meters are operating in about 5 distinct energy consumption profile patterns. 
This could suggest higher occupancy, lower energy efficiency of household or even
which groups of houses contain richer or poorer people.  

4. **graph_weather_energy_meter_clusters.html**
This graph looks at the relationship of energy consumption of meters and its
correlation with weather patterns. The first heat map shows a simple linear
pearson correlation while the second uses MSO style linear regression and plots
correlations. These correlations are then clustered and optimal number of clusters
determined. Finally, the clustering technique used is autoencoding and it is 
used to seperate different meters according to how closely they correlate with
weather. These are pinned to a map and colour coded. And clusters are also 
graphed as bar charts to show the variation in cluster correlation means. This result might be used for say, determining the type of load to be air conditioning 
(which might be highly correlated with weather or temperature) for particular households.
Of course, we note that while there is clustering of data, clusters are not as clearly
delineated and so different runs of the algoritm might yield different results. This 
suggests that load consumption patterns for the houses is not that distinct in the region 


Running the code
-----------------
TO RUN this code simply call:

1. If using conda, create python 3.11. conda environment and activate 
   <pre>conda create --name myenv python=3.11</pre>

2. Install requrements 
   <pre>pip install -r requirements.txt</pre> 

3. Run main.py 
   <pre>python main.py</pre>

4. To regenerate docs use
   <pre>pdoc main --html --output-dir . --force</pre>


Author & License
----------------
This code was authored by Siraj Sabihuddin with last edits on Dec 15, 2024. It is released
under GPL v2 license.

**Data Credit:** 
Data provided by HBKU 
'''

#-----------------------------------------------------------------------
# IMPORTS
#-----------------------------------------------------------------------
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam
from kneed import KneeLocator
from bokeh.plotting import figure, show, output_file
from bokeh.layouts import gridplot, column
from bokeh.palettes import Viridis256, Inferno256, RdYlGn
from bokeh.models import NumeralTickFormatter, DatetimeTickFormatter, Range1d, LinearAxis, ColorBar, BasicTicker, LinearColorMapper, Span, Div, Whisker, ColumnDataSource, LabelSet
from bokeh.transform import linear_cmap
from datetime import datetime
import folium
from pyproj import Transformer
import tempfile
from itertools import cycle
import statsmodels.api as sm
import os
# For CPU use of tensorflow since my GPU drivers are screwed ups
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

#-----------------------------------------------------------------------
# READ
#-----------------------------------------------------------------------
def read(files):
    '''
    Read the excel data. 

    Parameters
    ----------
    files : list of str
        A list of string filepaths from which to extract data. The file
        paths should be in xlsx format at the moment. 

    Returns
    -------
    data : list of dataframes
        Each item in the list is a single dataframe in the same order
        as the input file names. 
    '''
    # Read the xlsx file into a DataFrame
    data = [pd.read_excel(i) for i in files]

    # The data
    return data

#-----------------------------------------------------------------------
# GRAPH_ENERGY_METERID
#-----------------------------------------------------------------------
def graph_energy_meter(outputfile, data, rng=None):
    '''
    Provides a visualization of energy by meter id and stores it into an html file
    named according to parameters. Note that the rendered html generated by
    this function may take time to load. Be patient. This function really
    is only intended to provide a method of visualizing energy and meter
    data to better examine it. 

    Parameters
    ----------
    outputfile: str
        The name of the output html file for storing graphed results
    data : list of dataframes
        The first item in the list of data is the weather data and the second
        is the electrical data
    rng : list of int
        A [start, stop] list value pair to reduce the set of data graphed to within
        a smaller range. This is mostly to reduce the rendering time of generated
        html file in browser. If none, then just uses the entire data
    '''
    # Grab the data
    data_weather = data[1]
    data_electrical = data[0]

    # Extract columns where the header is a datetime object
    data_electrical_datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]
     
    # Group the electrical data by region
    data_electrical_grp = list(data_electrical.groupby('Area Num'))

    # Storing plots
    col_plots = []

    # Grab a subset of the data
    if (rng):
        data_electrical_grp_subset = data_electrical_grp[rng[0]:rng[1]]
    else:
        data_electrical_grp_subset = data_electrical_grp

    # Iterate through the grouped data
    for a in data_electrical_grp_subset:
        # Store the plots for a given date
        row_plots = []
        
        # Grab the area number
        area = list(a[1]['Area Num'])[0]

        # Iterate through datetimes
        for d in data_electrical_datetimes:
            # Get the date and associated power series for that date
            date = d.strftime("%B %Y")
            energy = a[1][d].to_numpy()
            id = a[1]['Elec Num'].to_numpy().astype(str) 

            # Create figure
            p = figure(title=f"{date}, Area: {area}", x_axis_label='Meter ID', y_axis_label='Energy', width=400, height=400, x_range=id)
            p.scatter(id, energy, size=10, color="navy", alpha=0.5)
            p.xaxis.formatter = NumeralTickFormatter(format="0")
            p.xaxis.major_label_orientation = 90
            p.xaxis.major_label_text_font_size = "5pt"
            row_plots.append(p)
        
        # Create a list of plots
        col_plots.append(row_plots)
    
    # Save to file
    layout = gridplot(col_plots)  # Arrange in a single row grid
    output_file(outputfile)
    show(layout)

#-----------------------------------------------------------------------
# GRAPH_ENERGY_MONTH
#-----------------------------------------------------------------------
def graph_energy_month(outputfile, data, rng=None):
    '''
    Provides a visualization of energy by month of year for every area and 
    every meter and stores it into an html file named according to parameters
    The right hand axis graph the monthly average weather data while the left
    hand axis graphs the monthly energy data. These are arranged into rows
    organized by Area Num. A single row contains all meters in the area. Note 
    that this function simply provides a method of visualization to better
    understand the data. 

    Parameters
    ----------
    outputfile: str
        The name of the output html file for storing graphed results
    data : list of dataframes
        The first item in the list of data is the weather data and the second
        is the electrical data
    rng : list of int
        A [start, stop] list value pair to reduce the set of data graphed to within
        a smaller range. This is mostly to reduce the rendering time of generated
        html file in browser. If none then use entire data set
    '''
    # Grab the data
    data_weather = data[1]
    data_electrical = data[0]

    # Extract columns where the header is a datetime object
    data_electrical_datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]
    dates = np.array(data_electrical_datetimes)

    # Group the electrical data by meterid
    data_electrical_grp = list(data_electrical.groupby('Area Num'))

    # Now grab the weather data for the year and accumulate it by month to produce an 
    # average monthly irradiances, temperatures, etc as a baseline for comparison of electrical power production data.
    irradiances = np.array(data_weather.groupby('Month')['GHI'].mean())
    temperatures = np.array(data_weather.groupby('Month')['Temperature'].mean())
    precipitations = np.array(data_weather.groupby('Month')['Precipitable Water'].mean())
    humidities = np.array(data_weather.groupby('Month')['Relative Humidity'].mean())

    # Storing plots
    col_plots = []

    # Grab a subset of the data
    if (rng):
        data_electrical_grp_subset = data_electrical_grp[rng[0]:rng[1]]
    else:
        data_electrical_grp_subset = data_electrical_grp

    # Iterate through the grouped data. Each group 
    # should contain a dataframe for a particular Area Num.
    for a in data_electrical_grp_subset:
        # Store the plots for a given date
        row_plots = []

        # Grab the area number
        area = list(a[1]['Area Num'])[0]

        # Grab the meterids for the particular area
        ids = a[1]['Elec Num'].to_numpy()

        # Iterate through datetimes
        for id in ids:
            # Get the date and associated power series for that date
            meter_data = a[1][a[1]['Elec Num'] == id]

            # Extract the energy values for the given ids
            energies = meter_data[data_electrical_datetimes].to_numpy()[0]

            ###################################
            # Creates a graph of dates v.s
            # energy values for every meter
            # in a given Area Num. 
            ###################################
            # Create figure with primary axis for dates vs energies
            p = figure(title=f"Area: {area}, MeterID: {id}", x_axis_label='Date', y_axis_label='Energy', width=700, height=400)
            p.scatter(dates, energies, size=10, color="black", alpha=1)

            ###################################
            # Adds additional vertical axis
            # and graph for Irradiance from
            # weather data
            ###################################
            # Add a secondary y-axis for irradiance
            p.extra_y_ranges = {"irradiance": Range1d(start=0, end=600)}
            irradiance_axis = LinearAxis(y_range_name="irradiance", axis_label="Irradiance", major_label_text_color="orange", major_tick_line_color="orange", axis_line_color = "orange", axis_label_text_color="orange")
            p.add_layout(irradiance_axis, 'right')

            # Plot irradiance data using the secondary y-axis
            p.line(dates, irradiances, line_width=2, color="orange", alpha=0.7, y_range_name="irradiance")

            ###################################
            # Adds additional vertical axis
            # and graph for temperature from
            # weather data
            ###################################
            # Add a third y-axis for temperature
            p.extra_y_ranges["temperature"] = Range1d(start=0, end=40)
            temperature_axis = LinearAxis(y_range_name="temperature", axis_label="Temperature", major_label_text_color="red", major_tick_line_color="red", axis_line_color = "red", axis_label_text_color="red")

            # Offset the temperature axis to avoid overlap
            p.add_layout(temperature_axis, 'right')
            temperature_axis.ticker.desired_num_ticks = 5

            # Plot temperature data using the third y-axis
            p.line(dates, temperatures, line_width=2, color="red", alpha=0.7, y_range_name="temperature")

            ###################################
            # Adds additional vertical axis
            # and graph for Precipitation from
            # weather data
            ###################################
            # Add a fourth y-axis for precipitation
            p.extra_y_ranges["precipitations"] = Range1d(start=0, end=3)
            precipitation_axis = LinearAxis(y_range_name="precipitations", axis_label="Precipitable Water", major_label_text_color="blue", major_tick_line_color="blue", axis_line_color = "blue", axis_label_text_color="blue")

            # Offset the precipitation axis to avoid overlap
            p.add_layout(precipitation_axis, 'right')
            precipitation_axis.ticker.desired_num_ticks = 5

            # Plot temperature data using the third y-axis
            p.line(dates, precipitations, line_width=2, color="blue", alpha=0.7, y_range_name="precipitations")

            ###################################
            # Adds additional vertical axis
            # and graph for Humidity from
            # weather data
            ###################################
            # Add a fifth y-axis for humidities
            p.extra_y_ranges["humidities"] = Range1d(start=0, end=100)
            humidities_axis = LinearAxis(y_range_name="humidities", axis_label="Relative Humidity", major_label_text_color="green", major_tick_line_color="green", axis_line_color = "green", axis_label_text_color="green")

            # Offset the precipitation axis to avoid overlap
            p.add_layout(humidities_axis, 'right')
            humidities_axis.ticker.desired_num_ticks = 5

            # Plot temperature data using the third y-axis
            p.line(dates, humidities, line_width=2, color="green", alpha=0.7, y_range_name="humidities")


            p.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
            p.xaxis.major_label_orientation = 90
            row_plots.append(p)
        
        # Create a list of plots
        col_plots.append(row_plots)
    
    # Save to file
    layout = gridplot(col_plots)  # Arrange in a single row grid
    output_file(outputfile)
    show(layout)

#-----------------------------------------------------------------------
# GRAPH_ENERGY_MONTH_METERID_CLUSTERS
#-----------------------------------------------------------------------
def graph_energy_meter_clusters (outputfile, data, rng=None):
    '''
    This function uses the following approaches to extract meaningful
    data about the energy relationship between meters in the data provided
    
    1. Uses a kmeans approach to cluster meters and extract the optimal
       number of meter clusters via the knee of the SSE graph. The SSE
       graph is created in an html file (left most graph)
    2. The meters are clustered by the optimal cluster size and their
       similarity in energy consumption pattern thus correlated. 
    3. The meters are each pinned to an openstreetmaps view and colour
       coded by the cluster they belong to. Added tooltip data is 
       added for each pin and different clusters can be turned off and on
       individually. A graph is added as a middle map graph to the same
       html graph file as step 1.
    4. Finally the assumed normal distribution statistics, namel the mean
       and standard deviation are extracted and then a set of line graphs
       mapped into the right most figure (color coded to map) are provided
       to indicate the distinct energy consumption patterns of each cluster
    
    Parameters
    ----------
    outputfile: str
        The name of the output html file for storing graphed results
    data : list of dataframes
        The first item in the list of data is the weather data and the second
        is the electrical data
    rng : list of int
        A [start, stop] list value pair to reduce the set of data graphed to within
        a smaller range. This is mostly to reduce the rendering time of generated
        html file in browser
    '''
    # Grab the data
    data_weather = data[1]
    data_electrical = data[0]

    ##################################################
    # Extract the month columns and associated 
    # meter energy data for those months
    ##################################################
    # Extract columns where the header is a datetime object
    data_electrical_datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]

    # Create a dataframe of Elec Num and monthly energy usage (including total)
    # and use this to produce a correlation matrix of every meter to every other
    # meter
    cols = data_electrical_datetimes
    if (rng):
        meter_data=data_electrical.iloc[rng[0]:rng[1]].copy()
    else:
        meter_data=data_electrical.copy()
    meter_data=meter_data[cols]

    ##################################################
    # Normaize meter data to perform clustering
    ##################################################
    # Start by normalizing the data
    # Preprocess and scale the data
    scaler = StandardScaler()
    # Fit and transform the data
    meter_data_normalized = scaler.fit_transform(meter_data)
    # Convert the normalized data back into a DataFrame
    meter_data_ = pd.DataFrame(meter_data_normalized, columns=meter_data.columns)

    ##################################################
    # Compute the clusters of meter energy 
    # consumption types and determine the optimal
    # cluster sizes 
    ##################################################
    # Determine the optimal number of clusters using the elbow method
    # Finds the optimal number of clusters (k) in a dataset by running K-Means 
    # clustering for a range of values for k and calculating Sum of Squared Errors (SSE) 
    # or inertia for each k. Identify "elbow point," where increasing k yields diminishing 
    # returns in reducing SSE.
    sse = []; n = 30
    for k in range(1, n):
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(meter_data_)
        sse.append(kmeans.inertia_)

    # Create the figure
    p = figure(title="K-Means Optimal Cluster Size", x_axis_label='No. Clusters', y_axis_label='SSE', width=400, height=400)
    p.line(list(range(1, n)), sse, line_width=2)
    p.scatter(list(range(1, n)), sse, size=8, color='red')

    # Use KneeLocator to find the elbow point
    kneedle = KneeLocator(list(range(1, n)), sse, curve='convex', direction='decreasing')

    # Get the elbow (knee) point
    optimalk = kneedle.elbow

    # Plot a vertical line for optimal k value
    vline = Span(location=optimalk, dimension='height', line_color='gray', line_width=1)
    p.add_layout(vline)

    # Fit the KMeans model
    # Replace with your chosen optimal number of clusters
    kmeans = KMeans(n_clusters=optimalk, random_state=42)
    clusters = kmeans.fit_predict(meter_data_)

    # Store the cluster numbers along with the meter ids and total energy
    # consumptions into the meter_data dataframe - we had removed some of 
    # these values from the origiinal data, now we're adding them 
    # back.
    meter_data['Cluster'] = clusters
    meter_data['Elec Num'] = data_electrical['Elec Num'].copy()
    meter_data['Total 19'] = data_electrical['Total 19'].copy()
    meter_data['Area Name'] = data_electrical['Area Name'].copy()
    meter_data['Area Num'] = data_electrical['Area Num'].copy()
    meter_data['X Coordinate'] = data_electrical['X Coordinate'].copy()
    meter_data['Y Coordinate'] = data_electrical['Y Coordinate'].copy()

    ##################################################
    # Grab the coordinate positions of meters, convert
    # and plot onto a map
    ##################################################
    # Define the transformer with the appropriate EPSG codes
    transformer = Transformer.from_crs("epsg:32636", "epsg:4326", always_xy=True)

    # List of coordinates extracted and converted to latitude and longitude
    coordinates = [(i, j) for i, j in zip(meter_data['X Coordinate'], meter_data['Y Coordinate'])]
    coordinates_lat_lon = [transformer.transform(x, y) for x, y in coordinates]

    # Map cluster numbers to colors using Viridis256 palette
    unique_clusters = sorted(set(clusters))
    
    # Define available Folium colors
    folium_colors = ['darkblue', 'lightgray', 'black', 'red', 'blue', 'white', 
                    'orange', 'darkgreen', 'pink', 'darkpurple', 'gray', 'darkred', 
                    'lightgreen', 'lightred', 'purple', 'cadetblue', 'beige', 
                    'lightblue', 'green']
    # Reduce this to the number of unique colours
    folium_colors = [folium_colors[i] for i in unique_clusters]

    # Map cluster numbers to available colors
    cluster_to_color = {cluster: folium_colors[i % len(folium_colors)] for i, cluster in enumerate(unique_clusters)}

    # Create a folium map centered around the first point
    m = folium.Map(location=coordinates_lat_lon[0], zoom_start=10, tiles='OpenStreetMap')

    # Create FeatureGroups for each color
    feature_groups = {color: folium.FeatureGroup(name=f'Cluster {color}', show=True).add_to(m) for color in folium_colors}

    # Add points to the map with colors based on clusters. We add a tooltip to each
    # marker to provide further information about the particular meter in the class
    for idx, (lat, lon) in enumerate(coordinates_lat_lon):
        # Grab the cluster_id for the current coordinate (lat, long)
        # Grab the meter data for the current cluster
        # Grab the colour for the current cluster
        cluster_id = clusters[idx]
        meter_data_ = meter_data.iloc[idx]
        color = cluster_to_color[cluster_id]

        # Construct a tool tip to display additional details 
        # for each location on map
        tooltip_text = f"<strong>Cluster ID:</strong> {cluster_id}<br> \
                         <strong>Area Name:</strong> {meter_data_['Area Name']}<br> \
                         <strong>Elec Num:</strong> {meter_data_['Elec Num']}<br> \
                         <strong>Coordinates:</strong> ({lat:.4f}, {lon:.4f})<br> \
                         <strong>Energy:</strong> {meter_data_['Total 19']}"
        
        # Add a location marker on the map for the current (lat, long) position
        folium.Marker([lat, lon], icon=folium.Icon(color=color), tooltip=tooltip_text).add_to(feature_groups[color])

    # Add LayerControl to toggle visibility of FeatureGroups
    folium.LayerControl().add_to(m)

    # Save the folium map to a temporary HTML file
    temp_map_file = tempfile.NamedTemporaryFile(delete=False, suffix='.html')
    m.save(temp_map_file.name)

    # Create a Bokeh Div to display the folium map
    map_div = Div(text=f'<iframe src="{temp_map_file.name}" width="700" height="400"></iframe> \
                         <br><h3 align="center" style="font-size:14px"><b>Meters Clustered by Similarity in Energy Consumption</b></h3>')

    ##################################################
    # Plot cluster meter energy means and standard 
    # deviations for each cluster in map
    ##################################################
    # Extract columns where the header is a datetime object
    data_electrical_datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]

    # Group meter data by Clusters
    meter_data_cluster_grp = list(meter_data.groupby('Cluster'))

    # Now we will graph the meter data for this cluster as a set of 
    # distinctly coloured lines on a single graph
    cp = figure(title=f"Meter Mean Energy per cluster", x_axis_label='Energy', y_axis_label='Date', width=400, height=400, y_range=(0, 20000))    
    cp.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
    cp.xaxis.major_label_orientation = 90

    # Iterate through each cluster's meter data. 
    for i in meter_data_cluster_grp:
        # Get the cluster id for the current dataframe
        cluster_id = i[0]

        # Convert the dates into a numpy array for graphing and
        # extract the energies associated with the dates and convert to numpy for graphing
        dates = np.array(data_electrical_datetimes)
        energies=i[1][data_electrical_datetimes].to_numpy()
        energies_mean = i[1][data_electrical_datetimes].mean(axis=0).to_numpy()
        energies_std = i[1][data_electrical_datetimes].std(axis=0).to_numpy()

        # Create a ColumnDataSource
        source = ColumnDataSource(data=dict(
            dates=dates,
            mean=energies_mean,
            upper=energies_mean + energies_std,
            lower=energies_mean - energies_std
        ))

        # Graph each of the line means and add error bars
        cp.line('dates', 'mean', source=source, line_width=2, color=folium_colors[cluster_id], legend_label=f"Cluster {cluster_id}, {folium_colors[cluster_id]}")
        cp.add_layout(Whisker(source=source, base='dates', upper='upper', lower='lower', line_color=folium_colors[cluster_id], line_alpha=0.4,upper_head=None, lower_head=None))
    
    # Adjust legend font sizing
    # Reduce spacing between legend items
    # Reduce padding around the legend
    # Reduce the height of the legend glyphs
    cp.legend.label_text_font_size = '7pt'
    cp.legend.spacing = 0  
    cp.legend.padding = 1
    cp.legend.glyph_height = 7  

    ###########################################
    # Store the data in an html graph file
    ###########################################
    # Save to file after arranging into a grid layout
    layout = gridplot([[p, map_div, cp]]) 
    output_file(outputfile)
    show(layout)

#-----------------------------------------------------------------------
# GRAPH_WEATHER_ENERGY_METER
#-----------------------------------------------------------------------
def graph_weather_energy_meter_clusters(outputfile, data, rng=None):
    '''
    Grabs the various weather parameters and grab those meters that
    are most highly correlated with weather patterns and separate them
    from those meters that have lower correlations. Use pearson correlation
    and linear regression to create correlations and then custer these with
    kmeans and autoencoders to determine the level of correlation to weather
    patterns for every meter. Graph these results and place pins on a map
    as well. Note that autoencoder can be a bit stochastic and can lead 
    to differing results for clusters on subsequent runs. It would be 
    good to run more than once if clusters end up as single clusters.
    Really, I'm just using autoencoders for fun. In fact, standard kmeans
    will probably respond just as well and more deterministically.    

    Parameters
    ----------
    outputfile: str
        The name of the output html file for storing graphed results
    data : list of dataframes
        The first item in the list of data is the weather data and the second
        is the electrical data
    rng : list of int
        A [start, stop] list value pair to reduce the set of data graphed to within
        a smaller range. This is mostly to reduce the rendering time of generated
        html file in browser
    '''
    # Grab the data
    data_weather = data[1]
    data_electrical = data[0]

    # Now grab the weather data for the year and accumulate it by month to produce an 
    # average monthly irradiances, temperatures, etc as a baseline for comparison of electrical power production data.
    # Note that I assume a normal distribution. 
    irradiances = data_weather.groupby('Month')['GHI'].mean()
    albedos = data_weather.groupby('Month')['Surface Albedo'].mean()
    temperatures = data_weather.groupby('Month')['Temperature'].mean()
    precipitations = data_weather.groupby('Month')['Precipitable Water'].mean()
    humidities = data_weather.groupby('Month')['Relative Humidity'].mean()
    pressure = data_weather.groupby('Month')['Pressure'].mean()
    wind_direction = data_weather.groupby('Month')['Wind Direction'].mean()
    wind_speed = data_weather.groupby('Month')['Wind Speed'].mean()
    
    # Extract columns pertaining to the dates (months) for the available eneryg data
    datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]

    # Create a dataframe containing the monthly meter data for the datetimes extracted
    # and the months extracted for the weather data. 
    if (rng):
        meter_data=data_electrical.iloc[rng[0]:rng[1]].copy()
    else:
        meter_data=data_electrical.copy()
    meter_ids = meter_data['Elec Num']
    meter_data=meter_data[datetimes]
    meter_data['Elec Num'] = meter_ids.copy()
    meter_data.set_index('Elec Num', inplace=True)

    # Transpose the meter_data so that the index is setup as datetimes
    meter_data = meter_data.T
    meter_data['datetimes'] = datetimes.copy()
    meter_data.set_index('datetimes', inplace=True)

    # Reconstruct the data frame. 
    weather_data = pd.DataFrame({
            'GHI' : irradiances,
            'Surface Albedo' : albedos,
            'Temperature' : temperatures,
            'Precipitable Water' : precipitations,
            'Relative Humidity' : humidities, 
            'Pressure' : pressure,
            'Wind_direction' : wind_direction,
            'Wind_speed' : wind_speed,
         })

    # replace the index of the weather data (i.e the month column)
    # with datetimes extracted from meter data
    weather_data['datetimes'] = datetimes.copy()
    weather_data.set_index('datetimes', inplace=True)

    ####################################################
    # Does simple linear correlation between weather
    # parameters and energy profiles of each meter
    ####################################################
    # Loop over each weather parameter and compute a correlation
    # matrix for it with meter_data
    correlations0 = pd.DataFrame(columns=meter_data.columns)

    for col in meter_data.columns:
        # Calculate Pearson correlation of each column with the target column
        # note that this assumes that there is a linear relationship without lag 
        # between the weather parameters on a monthly basis and energy production
        # This will perform poorly if this is not the case. 
        correlation = weather_data.corrwith(meter_data[col])
        correlations0[col]=correlation

    # Convert the correlation matrix into a numpy 2d matrix
    corr = correlations0.to_numpy()
    nrows, ncols = corr.shape

    # Create a figure
    p0 = figure(title="Pearson (linear) Correlation Meter Energy v.s. Weather Params", x_axis_label='Meter ID', y_axis_label='Weather Param', x_range=(0, ncols), y_range=(0, nrows), 
            width=600, height=400)

    # Create a color mapper
    mapper = LinearColorMapper(palette=RdYlGn[11], low=corr.min(), high=corr.max())

    # Use image to display the matrix
    p0.image(image=[corr], x=0, y=0, dw=ncols, dh=nrows, color_mapper=mapper)

    # Add color bar
    color_bar = ColorBar(color_mapper=mapper, location=(0, 0))
    p0.add_layout(color_bar, 'right')

    # Adjust ticker location to be centre of grid
    p0.xaxis.ticker = [i + 0.5 for i in range(ncols)]
    p0.yaxis.ticker = [i + 0.5 for i in range(nrows)]  

    # Remove xaxis ticks since we have meter ids here that really
    # don't provide any meaningful information too the user beyond
    # that they are meter ids. Also hide any numbers. s
    p0.xaxis.minor_tick_line_color = None
    p0.xaxis.major_tick_line_color = None
    p0.xaxis.major_label_text_font_size = '0pt'

    # Replace the numerical values on the xaxis and yaxis with labels. Note 
    # that this is relatively easy for the yaxis it is harder for the 
    # xaxis since there is 
    p0.yaxis.major_label_overrides = {i + 0.5: correlations0.index[i] for i in range(nrows)}
    
    ####################################################
    # Do a more sophisticated approach to correlate
    # to a single measure using all weather parameters
    # collectively with meter using Multiple Linear 
    # Regression (one dependent variable)
    ####################################################
    # Iterate over each meter to perform regression
    r_squared = []
    for meter in meter_data.columns:
        # Define the dependent variable (energy meter data)
        y = meter_data[meter]

        # Define independent variables (weather data)
        X = weather_data

        # Add a constant to the model (intercept)
        X = sm.add_constant(X)

        # Fit the regression model
        model = sm.OLS(y, X).fit()

        # Get the R-squared value
        r_squared.append((model.rsquared, meter))

    # Grab the lists
    correlations1, meters  = zip(*r_squared)

    # Convert the meter ids into strings
    meters_str = [str(i) for i in meters] 

    # Prepare data for Bokeh
    source = ColumnDataSource(data=dict(
        meters_str=meters_str, 
        correlations1=correlations1
    ))

    # Create a figure
    p1 = figure(title="Multiple Linear Regression correlation of Energy of every Meter ID v.s. Weather Params", x_axis_label='Meter ID', y_axis_label='R-Squared Values', x_range=meters_str, width=600, height=400)
    p1.scatter(x='meters_str', y='correlations1', width=0.9, source=source)

    # Adjust x labels orientation and size
    # and remove tick marks
    p1.xaxis.major_label_orientation = 90
    p1.xaxis.major_label_text_font_size = "5pt"
    p1.xgrid.grid_line_color = None
    p1.xaxis.minor_tick_line_color = None
    p1.xaxis.major_tick_line_color = None
    
    # Label axis titles.
    p1.xaxis.axis_label = "Meter ID"
    p1.yaxis.axis_label = "R-squared Value"

    ###########################################
    # Use k-means to figure out the optimal
    # number of clusters. 
    ###########################################
    # Scale the correlation1 values obtained from linear regression
    scaler = StandardScaler()
    correlations1_scaled = scaler.fit_transform(np.array(correlations1).reshape(-1, 1))

    # Determine the optimal number of clusters using the elbow method
    # Finds the optimal number of clusters (k) in a dataset by running K-Means 
    # clustering for a range of values for k and calculating Sum of Squared Errors (SSE) 
    # or inertia for each k. Identify "elbow point," where increasing k yields diminishing 
    # returns in reducing SSE.
    sse = []; n = 30
    for k in range(1, n):
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(correlations1_scaled)
        sse.append(kmeans.inertia_)

    # Create the figure
    p2 = figure(title="K-Means Optimal Cluster Size", x_axis_label='No. Clusters', y_axis_label='SSE', width=600, height=400)
    p2.line(list(range(1, n)), sse, line_width=2)
    p2.scatter(list(range(1, n)), sse, size=8, color='red')

    # Use KneeLocator to find the elbow point
    kneedle = KneeLocator(list(range(1, n)), sse, curve='convex', direction='decreasing')

    # Get the elbow (knee) point
    optimalk = kneedle.elbow

    # Plot a vertical line for optimal k value
    vline = Span(location=optimalk, dimension='height', line_color='gray', line_width=1)
    p2.add_layout(vline)

    ###########################################
    # Use an autoencoder approach to clustering
    # of r-square values to determine distinct
    # profiles of energy data from meters as
    # they do / don't correlate to weather data
    ###########################################
    # Define the autoencoder model
    # Using a 1D latent space for simplicity
    input_dim = correlations1_scaled.shape[1]
    encoding_dim = 1 

    # Encoder & Decoder
    input_layer = Input(shape=(input_dim,))
    encoded = Dense(encoding_dim, activation='relu')(input_layer)
    decoded = Dense(input_dim, activation='sigmoid')(encoded)

    # Define the autoencoder, train the autoencoder, extract the encoder model
    autoencoder = Model(inputs=input_layer, outputs=decoded)
    autoencoder.compile(optimizer='adam', loss='mse')
    autoencoder.fit(correlations1_scaled, correlations1_scaled, epochs=50, batch_size=16, shuffle=True, verbose=0)
    encoder = Model(inputs=input_layer, outputs=encoded)
    encoded_data = encoder.predict(correlations1_scaled)

    # Perform K-Means clustering on the encoded data
    kmeans = KMeans(n_clusters=optimalk)
    clusters = kmeans.fit_predict(encoded_data)

    ##################################################
    # Grab the coordinate positions of meters, convert
    # and plot onto a map
    ##################################################
    # Define the transformer with the appropriate EPSG codes
    transformer = Transformer.from_crs("epsg:32636", "epsg:4326", always_xy=True)

    # Store the cluster numbers along with the meter ids and total energy
    # consumptions into the meter_data dataframe - we had removed some of 
    # these values from the origiinal data, now we're adding them 
    # back.
    meter_data = meter_data.T.copy()
    meter_data['Cluster'] = clusters
    meter_data['Correlation'] = list(correlations1)
    meter_data['Elec Num'] = list(data_electrical['Elec Num'])
    meter_data['Total 19'] = list(data_electrical['Total 19'])
    meter_data['Area Name'] = list(data_electrical['Area Name'])
    meter_data['Area Num'] = list(data_electrical['Area Num'])
    meter_data['X Coordinate'] = list(data_electrical['X Coordinate'])
    meter_data['Y Coordinate'] = list(data_electrical['Y Coordinate'])

    # List of coordinates extracted and converted to latitude and longitude
    coordinates = [(i, j) for i, j in zip(meter_data['X Coordinate'], meter_data['Y Coordinate'])]
    coordinates_lat_lon = [transformer.transform(x, y) for x, y in coordinates]

    # Grab the unique cluster numbers / ids
    unique_clusters = sorted(set(clusters))
    
    # Define available Folium colors
    folium_colors = ['darkblue', 'lightgray', 'black', 'red', 'blue', 'white', 
                    'orange', 'darkgreen', 'pink', 'darkpurple', 'gray', 'darkred', 
                    'lightgreen', 'lightred', 'purple', 'cadetblue', 'beige', 
                    'lightblue', 'green']
    # Reduce this to the number of unique colours
    folium_colors = [folium_colors[i] for i in unique_clusters]

    # Map cluster numbers to available colors
    cluster_to_color = {cluster: folium_colors[i % len(folium_colors)] for i, cluster in enumerate(unique_clusters)}

    # Create a folium map centered around the first point
    m = folium.Map(location=coordinates_lat_lon[0], zoom_start=10, tiles='OpenStreetMap')

    # Create FeatureGroups for each color
    feature_groups = {color: folium.FeatureGroup(name=f'Cluster {color}', show=True).add_to(m) for color in folium_colors}

    # Add points to the map with colors based on clusters. We add a tooltip to each
    # marker to provide further information about the particular meter in the class
    for idx, (lat, lon) in enumerate(coordinates_lat_lon):
        # Grab the cluster_id for the current coordinate (lat, long)
        # Grab the meter data for the current cluster
        # Grab the colour for the current cluster
        cluster_id = clusters[idx]
        meter_data_ = meter_data.iloc[idx]
        color = cluster_to_color[cluster_id]

        # Construct a tool tip to display additional details 
        # for each location on map
        tooltip_text = f"<strong>Cluster ID:</strong> {cluster_id}<br> \
                         <strong>Area Name:</strong> {meter_data_['Area Name']}<br> \
                         <strong>Elec Num:</strong> {meter_data_['Elec Num']}<br> \
                         <strong>Coordinates:</strong> ({lat:.4f}, {lon:.4f})<br> \
                         <strong>Energy:</strong> {meter_data_['Total 19']}<br> \
                         <strong>Correlation:</strong> {meter_data_['Correlation']}"
        
        # Add a location marker on the map for the current (lat, long) position
        folium.Marker([lat, lon], icon=folium.Icon(color=color), tooltip=tooltip_text).add_to(feature_groups[color])

    # Add LayerControl to toggle visibility of FeatureGroups
    folium.LayerControl().add_to(m)

    # Save the folium map to a temporary HTML file
    temp_map_file = tempfile.NamedTemporaryFile(delete=False, suffix='.html')
    m.save(temp_map_file.name)

    # Create a Bokeh Div to display the folium map
    p3 = Div(text=f'<iframe src="{temp_map_file.name}" width="600" height="400"></iframe> \
                         <br><h3 align="center" style="font-size:14px"><b>Meters Clustered by Correlation to Weather Params</b></h3>')


    ##################################################
    # Plot cluster meter energy means and standard 
    # deviations for each cluster in map
    ##################################################
    # Extract columns where the header is a datetime object
    data_electrical_datetimes = [col for col in data_electrical.columns if isinstance(col, datetime)]

    # Group meter data by Clusters
    meter_data_cluster_grp = list(meter_data.groupby('Cluster'))

    # Iterate through each cluster's meter data.
    cluster_ids = []
    correlations_mean = []
    correlations_std = [] 
    for i in meter_data_cluster_grp:
        # Get the cluster id for the current dataframe
        cluster_ids.append(i[0])

        # Convert the dates into a numpy array for graphing and
        # extract the correlations associated with the dates and convert to numpy for graphing
        correlations_mean.append((i[1]['Correlation']).to_numpy().mean())
        correlations_std.append((i[1]['Correlation']).to_numpy().std())

    # Create a ColumnDataSource
    source = ColumnDataSource(data=dict(
        cluster_ids=[f"Cluster {i}" for i in cluster_ids],
        correlations_mean=np.array(correlations_mean),
        upper=np.array(correlations_mean) + np.array(correlations_std),
        lower=np.array(correlations_mean) - np.array(correlations_std),
        colors=folium_colors
    ))

    # Now we will graph the meter data for this cluster as a set of 
    # distinctly coloured lines on a single graph
    p4 = figure(title=f"Meter Mean Weather Correlation per cluster", x_axis_label='Cluster ID', y_axis_label='Weather R-Squared Correlation', 
        y_range=(0, 1), x_range=[f"Cluster {i}" for i in cluster_ids], width=600, height=400)    

    # Graph each of the line means and add error bars
    p4.vbar(x='cluster_ids', top='correlations_mean', width=0.9, source=source, line_color='black', fill_color='colors', legend_field="cluster_ids")
    p4.add_layout(Whisker(source=source, base="correlations_mean", upper="upper", lower="lower", line_color = 'colors', upper_head=None, lower_head=None))

    ###########################################
    # Store the data in an html graph file
    ###########################################
    # Save to file after arranging into a grid layout
    layout = gridplot([[p0, p1, p2],[p3, p4, None]]) 
    output_file(outputfile)
    show(layout)

#-----------------------------------------------------------------------
# MAIN
#-----------------------------------------------------------------------
def main():
    '''
    The main program run thread. 
    '''
    # Load the excel data
    files = ['./electricity.xlsx', './weather.xlsx']
    data = read(files)

    # Graph the data
    graph_energy_meter('graph_energy_meter.html', data)
    graph_energy_month('graph_weather_energy_month.html', data)
    graph_energy_meter_clusters('graph_energy_meter_clusters.html',data)
    graph_weather_energy_meter_clusters('graph_weather_energy_meter_clusters.html', data)

if __name__ == "__main__":
    main()